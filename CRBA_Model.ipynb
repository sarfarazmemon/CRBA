{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rb8ok-rxlj6z"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import DenseNet201\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Bidirectional, Input, TimeDistributed, Attention, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import LayerNormalization, Add\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2MwwJTK3l_C9"
   },
   "outputs": [],
   "source": [
    "UCF_CRIME_PATH = '...../RAD_dataset/'\n",
    "LABELS = ['Accident', 'Carfire', 'Fighting', 'Snatching']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JNtTYrszmXNx"
   },
   "outputs": [],
   "source": [
    "def video_to_frames(video_path, max_frames=25):\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    interval = max(1, frame_count // max_frames)\n",
    "    for i in range(0, frame_count, interval):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.resize(frame, (224, 224))\n",
    "        frames.append(frame)\n",
    "        if len(frames) >= max_frames:\n",
    "            break\n",
    "    cap.release()\n",
    "    return np.array(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uEJLv_LXpawZ"
   },
   "outputs": [],
   "source": [
    "class VideoDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, video_paths, labels, batch_size, max_frames, num_classes):\n",
    "        self.video_paths = video_paths\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.max_frames = max_frames\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_paths) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_paths = self.video_paths[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_labels = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        batch_frames = [video_to_frames(path, self.max_frames) for path in batch_paths]\n",
    "        batch_frames = np.array(batch_frames)\n",
    "        batch_labels = to_categorical(batch_labels, self.num_classes)\n",
    "\n",
    "        return batch_frames, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cf1SPvBLpoMS"
   },
   "outputs": [],
   "source": [
    "def create_residual_bilstm_block(input_tensor, lstm_units):\n",
    "    x = Bidirectional(LSTM(lstm_units, return_sequences=True))(input_tensor)\n",
    "    attention_output = Attention()([x, x])\n",
    "    x = Add()([x, attention_output])  # Residual connection\n",
    "    x = LayerNormalization()(x)\n",
    "    return x\n",
    "\n",
    "def create_densenet_bilstm_attention_model(num_classes, lstm_units=128, num_blocks=3):\n",
    "    input_tensor = Input(shape=(None, 224, 224, 3))\n",
    "    base_model = DenseNet201(include_top=False, input_shape=(224, 224, 3), weights='imagenet')\n",
    "    base_model.trainable = False\n",
    "\n",
    "    x = TimeDistributed(base_model)(input_tensor)\n",
    "    x = TimeDistributed(GlobalAveragePooling2D())(x)\n",
    "\n",
    "    for _ in range(num_blocks):\n",
    "        x = create_residual_bilstm_block(x, lstm_units)\n",
    "\n",
    "    x = LSTM(lstm_units)(x)\n",
    "    output_tensor = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input_tensor, outputs=output_tensor)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zDkdNNCEp-Ga"
   },
   "outputs": [],
   "source": [
    "num_classes = len(LABELS)\n",
    "lstm_units = 128\n",
    "num_blocks = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UQAQ99_Bp_aJ"
   },
   "outputs": [],
   "source": [
    "model = create_densenet_bilstm_attention_model(num_classes=num_classes, lstm_units=lstm_units, num_blocks=num_blocks)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "video_paths = [os.path.join(UCF_CRIME_PATH, label, video) for label in LABELS for video in os.listdir(os.path.join(UCF_CRIME_PATH, label))]\n",
    "labels = [LABELS.index(label) for label in LABELS for _ in os.listdir(os.path.join(UCF_CRIME_PATH, label))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_o8UtPwRqZiM"
   },
   "outputs": [],
   "source": [
    "split_index = int(0.8 * len(video_paths))\n",
    "train_paths, val_paths = video_paths[:split_index], video_paths[split_index:]\n",
    "train_labels, val_labels = labels[:split_index], labels[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uKe3jyeSqcMq"
   },
   "outputs": [],
   "source": [
    "train_generator = VideoDataGenerator(train_paths, train_labels, batch_size=8, max_frames=25, num_classes=num_classes)\n",
    "val_generator = VideoDataGenerator(val_paths, val_labels, batch_size=8, max_frames=25, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3aReBn_cqej6"
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, validation_data=val_generator, epochs=50)\n",
    "model.save('model.h5')\n",
    "y_true = val_labels\n",
    "y_pred_probs = model.predict(val_generator)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FaBrIC8oqsEh"
   },
   "outputs": [],
   "source": [
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=LABELS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5tZIbWsOqxaq"
   },
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Red\", xticklabels=LABELS, yticklabels=LABELS)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ihHPRuncrKqi"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(num_classes):\n",
    "    fpr, tpr, _ = roc_curve(to_categorical(y_true, num_classes)[:, i], y_pred_probs[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f'{LABELS[i]} (AUC = {roc_auc:.2f})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9hNSg4wGrNOK"
   },
   "outputs": [],
   "source": [
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-EeEN3L1rjca"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AHC6blh3rsTS"
   },
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nBKt38kJsTvK"
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
